{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, let's install the OpenAI gym and Atari environment:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: gym in /home/elyes/anaconda3/lib/python3.6/site-packages (0.11.0)\n",
      "Requirement already satisfied: scipy in /home/elyes/anaconda3/lib/python3.6/site-packages (from gym) (1.2.1)\n",
      "Requirement already satisfied: numpy>=1.10.4 in /home/elyes/anaconda3/lib/python3.6/site-packages (from gym) (1.15.4)\n",
      "Requirement already satisfied: pyglet>=1.2.0 in /home/elyes/anaconda3/lib/python3.6/site-packages (from gym) (1.3.2)\n",
      "Requirement already satisfied: six in /home/elyes/anaconda3/lib/python3.6/site-packages (from gym) (1.12.0)\n",
      "Requirement already satisfied: requests>=2.0 in /home/elyes/anaconda3/lib/python3.6/site-packages (from gym) (2.21.0)\n",
      "Requirement already satisfied: future in /home/elyes/anaconda3/lib/python3.6/site-packages (from pyglet>=1.2.0->gym) (0.17.1)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in /home/elyes/anaconda3/lib/python3.6/site-packages (from requests>=2.0->gym) (2.8)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /home/elyes/anaconda3/lib/python3.6/site-packages (from requests>=2.0->gym) (3.0.4)\n",
      "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /home/elyes/anaconda3/lib/python3.6/site-packages (from requests>=2.0->gym) (1.24.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/elyes/anaconda3/lib/python3.6/site-packages (from requests>=2.0->gym) (2018.11.29)\n"
     ]
    }
   ],
   "source": [
    "!pip install gym gym[atari]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's import the needed libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym, time\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from skimage import color"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's import Keras for our model later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Input, Flatten, Dense, Concatenate, Multiply, MaxPooling2D\n",
    "from keras.layers.convolutional import Conv2D\n",
    "from keras.models import Model, Sequential\n",
    "from keras.optimizers import RMSprop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cartpole example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This example shows how to use an OpenAI gym environment.\n",
    "First, we choose and init the environment:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.0072027 ,  0.04302043, -0.01092955,  0.01145781])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env = gym.make('CartPole-v0')\n",
    "env.reset()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we iterate for a big number of times. Each time, we do the following:\n",
    "* Render the environment\n",
    "* Get the observation, the reward and the `done` variable (it indicates whether we lost or not\n",
    "* (Optional) Sleep for 20ms, makes the animation smoother\n",
    "* (Optional) If we lost (`done == True`), reset the environment\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "for _ in range(50):\n",
    "    env.render()\n",
    "    obs, rew, done, info = env.step(env.action_space.sample()) # take a random action\n",
    "    time.sleep(0.02)\n",
    "    # Comment the two following lines to see cases of \"failure\"\n",
    "    #if done:\n",
    "    #   env.reset()\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`obs` is an array of length 4, whose values are: <br/>\n",
    "`[position of cart, velocity of cart, angle of pole, rotation rate of pole]`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BattleZone environment\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Actually, there are 12 environments. The main difference is the observation type:\n",
    "* The \"normal\" environments: observations are the frames of the game. They are bigger and more complex to analyse, but more intuitive.\n",
    "* The RAM environments: observations are a 128-byte arrays, representing the RAM of the Atari console. Lighter to use, but we do not know what each byte represents.\n",
    "\n",
    "The environment is provided in binary so we cannot modify it. Besides, it is hard to replicate the logic behind the spawning of enemies, so we chose to use the OpenAI environments directly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "battlezone_envs = ['BattleZone-v0', \n",
    "        'BattleZone-v4',\n",
    "        'BattleZoneDeterministic-v0', \n",
    "        'BattleZoneDeterministic-v4', \n",
    "        'BattleZoneNoFrameskip-v0', \n",
    "        'BattleZoneNoFrameskip-v4',\n",
    "        'BattleZone-ram-v0',\n",
    "        'BattleZone-ram-v4',\n",
    "        'BattleZone-ramDeterministic-v0', \n",
    "        'BattleZone-ramDeterministic-v4', \n",
    "        'BattleZone-ramNoFrameskip-v0',\n",
    "        'BattleZone-ramNoFrameskip-v4']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normal environment:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "env_number = 0\n",
    "env = gym.make(battlezone_envs[env_number])\n",
    "\n",
    "env.reset()\n",
    "for _ in range(200):\n",
    "    env.render()\n",
    "    obs, rew, done, info = env.step(env.action_space.sample()) # take a random action\n",
    "    time.sleep(0.02)\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(210, 160, 3)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "obs.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We try to get the dimensions of the interesting parts of the observation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f9e7a54b438>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(obs[3:36,74:96])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f9e79ccf828>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(obs[38:178,8:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_gray(img):\n",
    "    # Convert images to grayscale with values between 0 and 1\n",
    "    return color.rgb2gray(img).astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def downsample(img):\n",
    "    # Downsampling an image for faster computing\n",
    "    return img[::2, ::2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing(obs):\n",
    "    radar = obs[3:36,74:96]\n",
    "    scene = obs[38:178,8:]\n",
    "    radar = to_gray(radar)\n",
    "    scene = downsample(to_gray(scene))\n",
    "    return radar, scene"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "radar, scene = preprocessing(obs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f9e79c38780>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(scene, cmap=\"gray\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(33, 22) (70, 76)\n"
     ]
    }
   ],
   "source": [
    "print(radar.shape, scene.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Agent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will be giving the model a number of frames at a time (the time of the last projectile sent can be a determining factor, so the agent may need it)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_frames = 2 #Number of input frames per input\n",
    "n_actions = 18 #Dimension of action space\n",
    "batch_size = 1 #Number of entries (states+actions) to feed the NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_net():\n",
    "     # Shapes of entries\n",
    "    scene_shape = (70, 76, n_frames) # We will be using the number of frames as the number of channels \n",
    "    radar_shape = (33,22, n_frames)\n",
    "    \n",
    "    # Input layers\n",
    "    scene_inp = Input(shape=scene_shape, name='scenes')#, batch_shape=(n_frames, 70, 76))\n",
    "    radar_inp = Input(shape=radar_shape, name='radars')#, batch_shape=(n_frames, 33, 22))\n",
    "    actions_inp = Input((n_actions,), name='actions')\n",
    "    \n",
    "    # First convolution layers\n",
    "    conv1_1 = Conv2D(filters=8, kernel_size=(8, 8), strides=(4, 4), activation='relu', data_format=\"channels_last\")(scene_inp)\n",
    "    conv2_1 = Conv2D(filters=8, kernel_size=(4, 4), strides=(2, 2), activation='relu', data_format=\"channels_last\")(radar_inp)\n",
    "    \n",
    "    # First maxpooling attempt\n",
    "    maxpool1_1 = MaxPooling2D(pool_size=(8, 8), strides=(4, 4))(conv1_1)\n",
    "    maxpool2_1 = MaxPooling2D(pool_size=(4, 4), strides=(2, 2))(conv2_1)\n",
    "    \n",
    "    # Flattening results\n",
    "    flattened_1 = Flatten()(maxpool1_1)\n",
    "    flattened_2 = Flatten()(maxpool2_1)\n",
    "    \n",
    "    # Concatenating the results of the two entries\n",
    "    concat = Concatenate(axis=1)([flattened_1, flattened_2])\n",
    "    \n",
    "    # Output layer\n",
    "    output = Dense(n_actions, activation='relu')(concat)\n",
    "    \n",
    "    # Multiply by the actions\n",
    "    filtered_output = Multiply()([output, actions_inp])\n",
    "    \n",
    "    # Creating the model\n",
    "    model = Model(input=[scene_inp, radar_inp, actions_inp], \n",
    "                  output=filtered_output,\n",
    "                 )\n",
    "    \n",
    "    # Optimizer choice and tuning\n",
    "    rms = RMSprop(lr = 0.00025)\n",
    "    \n",
    "    # Compiling\n",
    "    model.compile(optimizer=rms, loss='mse')\n",
    "    \n",
    "    return model\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nor_env_net():\n",
    "    \n",
    "    # Shapes of entries\n",
    "    scene_shape = (70, 76, n_frames) # We will be using the number of frames as the number of channels \n",
    "    radar_shape = (33,22, n_frames)\n",
    "    \n",
    "    # Input layers\n",
    "    scene_inp = Input(scene_shape, name='scenes')#, batch_shape=(4, 70, 76))\n",
    "    radar_inp = Input(radar_shape, name='radars')#, batch_shape=(4, 33, 22))\n",
    "    actions_inp = Input((n_actions,), name='actions')\n",
    "    \n",
    "    # First convolution layers\n",
    "    conv1_1 = Conv2D(filters=16, kernel_size=(8, 8), strides=(4, 4), activation='relu')(scene_inp)\n",
    "    conv2_1 = Conv2D(filters=16, kernel_size=(4, 4), strides=(2, 2), activation='relu')(radar_inp)\n",
    "    \n",
    "    # First maxpooling attempt\n",
    "    # maxpool1_1 = MaxPooling2D(pool_size=(8, 8), strides=(4, 4))(conv1_1)\n",
    "    # maxpool2_1 = MaxPooling2D(pool_size=(4, 4), strides=(2, 2))(conv2_1)\n",
    "    \n",
    "    # Second convolutional layers\n",
    "    conv1_2 = Conv2D(filters=32, kernel_size=(4, 4), strides=(2, 2), activation='relu')(conv1_1)\n",
    "    conv2_2 = Conv2D(filters=32, kernel_size=(2, 2), strides=(1, 1), activation='relu')(conv2_1)\n",
    "    \n",
    "    # Second maxpooling attempt\n",
    "    maxpool1_2 = MaxPooling2D(pool_size=(4, 4), strides=(2, 2))(conv1_2)\n",
    "    maxpool2_2 = MaxPooling2D(pool_size=(2, 2), strides=(1, 1))(conv2_2)\n",
    "    \n",
    "    # Flattening results\n",
    "    flattened_1 = Flatten('channels_first')(maxpool1_2)\n",
    "    flattened_2 = Flatten('channels_first')(maxpool2_2)\n",
    "    \n",
    "    # Concatenating the results of the two entries\n",
    "    concat = Concatenate(axis=1)([flattened_1, flattened_2])\n",
    "    \n",
    "    # Applying a fully-connected layer\n",
    "    hidden_layer = Dense(256, activation='relu')(concat)\n",
    "    \n",
    "    # Output layer\n",
    "    output = Dense(n_actions, activation='relu')(hidden_layer)\n",
    "    \n",
    "    # Multiply by the actions\n",
    "    filtered_output = Multiply()([output, actions_inp])\n",
    "    \n",
    "    # Creating the model\n",
    "    model = Model(input=[scene_inp, radar_inp, actions_inp], \n",
    "                  output=filtered_output,\n",
    "                 )\n",
    "    \n",
    "    # Optimizer choice and tuning\n",
    "    rms = RMSprop(lr = 0.00025)\n",
    "    \n",
    "    # Compiling\n",
    "    model.compile(optimizer=rms, loss='mse')\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/elyes/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:34: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=[<tf.Tenso..., outputs=Tensor(\"mu...)`\n"
     ]
    }
   ],
   "source": [
    "from keras.utils import plot_model\n",
    "#model = nor_env_net()\n",
    "model = sample_net()\n",
    "plot_model(model,\n",
    "           to_file='model.png',\n",
    "           show_shapes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "scenes = list()\n",
    "radars = list()\n",
    "radar, scene = preprocessing(obs)\n",
    "\n",
    "for i in range(n_frames):\n",
    "    radars.append(radar)\n",
    "    scenes.append(scene)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 33, 22)\n",
      "(2, 70, 76)\n"
     ]
    }
   ],
   "source": [
    "s1 = (len(radars), radar.shape[0], radar.shape[1])\n",
    "s2 = (len(scenes), scene.shape[0], scene.shape[1])\n",
    "print(s1)\n",
    "print(s2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.2806306, 0.2806306, 0.2806306, 0.2806306, 0.2806306, 0.2806306,\n",
       "       0.2806306, 0.2806306, 0.2806306, 0.2806306, 0.2806306, 0.2806306,\n",
       "       0.2806306, 0.2806306, 0.2806306, 0.2806306, 0.2806306, 0.2806306,\n",
       "       0.2806306, 0.2806306, 0.2806306, 0.2806306, 0.2806306, 0.2806306,\n",
       "       0.2806306, 0.2806306, 0.2806306, 0.2806306, 0.2806306, 0.2806306,\n",
       "       0.2806306, 0.2806306, 0.2806306, 0.2806306, 0.2806306, 0.2806306,\n",
       "       0.2806306, 0.2806306, 0.2806306, 0.2806306, 0.2806306, 0.2806306,\n",
       "       0.2806306, 0.2806306, 0.2806306, 0.2806306, 0.2806306, 0.2806306,\n",
       "       0.2806306, 0.2806306, 0.2806306, 0.2806306, 0.2806306, 0.2806306,\n",
       "       0.2806306, 0.2806306, 0.2806306, 0.2806306, 0.2806306, 0.2806306,\n",
       "       0.2806306, 0.2806306, 0.2806306, 0.2806306, 0.2806306, 0.2806306,\n",
       "       0.2806306, 0.2806306, 0.2806306, 0.2806306, 0.2806306, 0.2806306,\n",
       "       0.2806306, 0.2806306, 0.2806306, 0.2806306], dtype=float32)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scenes[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"for i in range(s1[0]):\n",
    "    for j in range(s1[1]):\n",
    "        for k in range(s1[2]):\n",
    "            radars_array[i,j,k] = radars[i][j,k]\n",
    "            \n",
    "for i in range(s2[0]):\n",
    "    for j in range(s2[1]):\n",
    "        for k in range(s2[2]):\n",
    "            scenes_array[i,j,k] = scenes[i][j,k]\n",
    "\"\"\"\n",
    "radars = np.reshape(radars, (batch_size, radar.shape[0], radar.shape[1], n_frames))\n",
    "scenes = np.reshape(scenes, (batch_size, scene.shape[0], scene.shape[1], n_frames))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 33, 22, 2)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "radars.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lotfi/.local/lib/python3.6/site-packages/ipykernel_launcher.py:46: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=[<tf.Tenso..., outputs=Tensor(\"mu...)`\n"
     ]
    }
   ],
   "source": [
    "model = nor_env_net()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "l = model.predict([scenes, radars, np.ones((1,18))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax(l)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our model being already defined, we will now implement a function that will run a fitting iteration: We will be using a Deep Q-learning approach, improving our network everytime the agent makes an action."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will be using a buffer (a ringed buffer specifically) in order to put a limit to the memory usage (and prevent any saturation or malfunctioning of our agent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RingBuf:\n",
    "    \n",
    "    def __init__(self, size):\n",
    "        # We allocate one extra element, so that self.start == self.end always means the buffer is empty\n",
    "        self.data = [None] * (size + 1) # Size will indicate the size of memory we want to allocate\n",
    "        self.start = 0\n",
    "        self.end = 0\n",
    "        \n",
    "    def append(self, element):\n",
    "        self.data[self.end] = element\n",
    "        self.end = (self.end + 1) % len(self.data)\n",
    "        # end == start means the buffer has one too many element. \n",
    "        # We then remove the first element by incrementing start.\n",
    "        if (self.end == self.start):\n",
    "            self.start = (self.start + 1) % len(self.data)\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        return self.data[(self.start + index) % len(self.data)]\n",
    "    \n",
    "    def __len__(self):\n",
    "        if (self.end < self.start):\n",
    "            return (self.end + len(self.data) - self.start)\n",
    "        else:\n",
    "            return (self.end - self.start)\n",
    "        \n",
    "    def __iter__(self):\n",
    "        for i in range(len(self)):\n",
    "            yield self[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def epsilon_from_iter(i):\n",
    "    if (i > 1e6):\n",
    "        return 0.1\n",
    "    else:\n",
    "        return (1 - 1e-6 * 0.9 * i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import deque\n",
    "from copy import deepcopy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_iteration(model, gamma, start_scenes, start_radars, actions, rewards, next_scenes, next_radars, is_terminal):\n",
    "    \"\"\"\n",
    "    Params:\n",
    "    - model: The DQN defined in the last cell\n",
    "    - gamma: \"Discount factor\" (should be 0.99)\n",
    "    - start_scenes & start_radars: starting states\n",
    "    - actions: array of one-hot encoded actions corresponding to the start states\n",
    "    - rewards: array of rewards corresponding to the start states and actions\n",
    "    - next_scenes & next_radars: the resulting states corresponding to the start states and actions\n",
    "    - is_terminal: boolean array of whether the resulting state is terminal\n",
    "    \n",
    "    \"\"\"\n",
    "    # First, we predict the Q values of the next states. We pass ones as the \"mask\".\n",
    "    next_Q_values = model.predict([next_scenes, next_radars, np.ones((1, n_actions))])\n",
    "    \n",
    "    # The Q value a terminal state is 0 by definition\n",
    "    next_Q_values[is_terminal] = 0\n",
    "    \n",
    "    # We apply the formula of the Q value\n",
    "    Q_values = rewards + gamma * np.max(next_Q_values, axis=1)\n",
    "    \n",
    "    # Fit the model.\n",
    "    model.fit([start_scenes, start_radars, actions], actions * Q_values[:, None], nb_epoch=1, batch_size=len(start_scenes), verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def choose_action(model, stacked_radars, stacked_scenes):\n",
    "    # Choose the best action according to the model's prediction\n",
    "    \n",
    "    #Initializing\n",
    "    radars = list(stacked_radars)\n",
    "    scenes = list(stacked_scenes)\n",
    "\n",
    "        \n",
    "    # Reshaping for the model to use (typically 4 frames of each type, as the model has 4 input channels)\n",
    "    radars = np.reshape(radars, (batch_size, radars[0].shape[0], radars[0].shape[1], n_frames))\n",
    "    scenes = np.reshape(scenes, (batch_size, scenes[0].shape[0], scenes[0].shape[1], n_frames))\n",
    "    \n",
    "    prediction = model.predict([scenes, radars, np.ones((1,n_actions))])\n",
    "    \n",
    "    return np.argmax(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stack_frames(stacked_radars, stacked_scenes, observation):\n",
    "    radar, scene = preprocessing(observation)\n",
    "    if (len(stacked_radars) < n_frames):\n",
    "        for _ in range(n_frames):\n",
    "            stacked_radars.append(radar)\n",
    "            stacked_scenes.append(scene)\n",
    "    else:\n",
    "        stacked_radars.append(radar)\n",
    "        stacked_scenes.append(scene)\n",
    "    return stacked_radars, stacked_scenes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_game(n_games, model):\n",
    "    \n",
    "    gamma = 0.99\n",
    "    i = 0\n",
    "    rew_max = 0\n",
    "    \n",
    "    for _ in range(n_games):\n",
    "        \n",
    "        rew_total = 0\n",
    "        env.reset()\n",
    "        action = 0\n",
    "        \n",
    "        done = False\n",
    "        is_terminal = [False] * n_actions\n",
    "        \n",
    "        stacked_scenes = deque([], maxlen=n_frames)\n",
    "        stacked_radars = deque([], maxlen=n_frames)\n",
    "        \n",
    "        previous_scenes = list()\n",
    "        previous_radars = list()\n",
    "        \n",
    "        while not done :\n",
    "            env.render()\n",
    "            observation, rew, done, info = env.step(action)\n",
    "            \n",
    "            previous_radars, previous_scenes = deepcopy(stacked_radars), deepcopy(stacked_scenes)\n",
    "            \n",
    "            stacked_radars, stacked_scenes = stack_frames(stacked_radars,\n",
    "                                                          stacked_scenes,\n",
    "                                                          observation)\n",
    "            \n",
    "            is_terminal = np.reshape(is_terminal, (1, n_actions))\n",
    "            \n",
    "            if rew_total == 0:\n",
    "                previous_radars, previous_scenes = deepcopy(stacked_radars), deepcopy(stacked_scenes)\n",
    "            \n",
    "            if np.random.uniform() > epsilon_from_iter(i) and len(stacked_radars) == n_frames:\n",
    "                action = choose_action(model, stacked_radars, stacked_scenes)\n",
    "            else:\n",
    "                action = env.action_space.sample()\n",
    "            \n",
    "            if done:\n",
    "                is_terminal[0,action] = True\n",
    "            \n",
    "            # Actions one-hot vector\n",
    "            actions = np.zeros((1,n_actions))\n",
    "            actions[0,action] = 1\n",
    "            \n",
    "            # Reshaping for the model\n",
    "            start_scenes = np.reshape(list(previous_scenes), (batch_size, previous_scenes[0].shape[0], previous_scenes[0].shape[1], n_frames))\n",
    "            start_radars = np.reshape(list(previous_radars), (batch_size, previous_radars[0].shape[0], previous_radars[0].shape[1], n_frames))\n",
    "            next_scenes = np.reshape(list(stacked_scenes), (batch_size, stacked_scenes[0].shape[0], stacked_scenes[0].shape[1], n_frames))\n",
    "            next_radars = np.reshape(list(stacked_radars), (batch_size, stacked_radars[0].shape[0], stacked_radars[0].shape[1], n_frames))\n",
    "            \n",
    "            # Fitting iteration\n",
    "            fit_iteration(model, gamma, start_scenes, start_radars, actions, rew, next_scenes, next_radars, is_terminal)\n",
    "\n",
    "            i += 1\n",
    "            rew_total += rew\n",
    "            \n",
    "        rew_max = max(rew_max, rew_total)\n",
    "        env.close()\n",
    "    \n",
    "    return rew_max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lotfi/.local/lib/python3.6/site-packages/ipykernel_launcher.py:23: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "9000.0"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_game(10, model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RAM environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "env_number = 6\n",
    "env = gym.make(battlezone_envs[env_number])\n",
    "\n",
    "env.reset()\n",
    "for _ in range(100):\n",
    "    env.render()\n",
    "    obs, rew, done, info = env.step(env.action_space.sample()) # take a random action\n",
    "    time.sleep(0.02)\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(128,)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "obs.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
