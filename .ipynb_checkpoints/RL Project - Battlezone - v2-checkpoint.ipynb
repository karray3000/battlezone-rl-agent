{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, let's install the OpenAI gym and Atari environment:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install gym gym[atari]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Needed imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym, time\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from skimage import color"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import deque\n",
    "from copy import deepcopy\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BattleZone environment\n",
    "Actually, there are 12 environments. The main difference is the observation type:\n",
    "* The \"normal\" environments: observations are the frames of the game. They are bigger and more complex to analyse, but more intuitive.\n",
    "* The RAM environments: observations are a 128-byte arrays, representing the RAM of the Atari console. Lighter to use, but we do not know what each byte represents.\n",
    "\n",
    "The environment is provided in binary so we cannot modify it. Besides, it is hard to replicate the logic behind the spawning of enemies, so we chose to use the OpenAI environments directly. Moreover, the RAM environments are not interpretable, so we go for environments where the observation is the raw image.\n",
    "\n",
    "List of all environments (we choose the first one):\n",
    "\n",
    "```'BattleZone-v0', \n",
    "'BattleZone-v4',\n",
    "'BattleZoneDeterministic-v0', \n",
    "'BattleZoneDeterministic-v4', \n",
    "'BattleZoneNoFrameskip-v0', \n",
    "'BattleZoneNoFrameskip-v4',\n",
    "'BattleZone-ram-v0',\n",
    "'BattleZone-ram-v4',\n",
    "'BattleZone-ramDeterministic-v0', \n",
    "'BattleZone-ramDeterministic-v4', \n",
    "'BattleZone-ramNoFrameskip-v0',\n",
    "'BattleZone-ramNoFrameskip-v4'```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chosen environment: ```BattleZone-v4```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Global variable for rendering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "RENDER = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = gym.make('BattleZone-v4')\n",
    "_ = env.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "for _ in range(200):\n",
    "    obs, rew, done, info = env.step(env.action_space.sample()) # take a random action\n",
    "    if RENDER:\n",
    "        env.render()\n",
    "        time.sleep(0.02)\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observation (210x160 RGB image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7fbee38cf4a8>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAANEAAAD8CAYAAADpCEEHAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAAEwxJREFUeJzt3X+wXGV9x/H3xygiasuPxBCStAlOtANqo2SUmSqiFkXGToyjEdpRVKYRC53o2GmDdhTtP2pFm46VmTBkgI4CoYAyjrUiteI4jZJgCASMCRiaXG4SbtAQBcXAt3/sWd37Y++e3WfPnnN2P6+ZM/fss2f3PGf3fu/3Oc89+11FBGbWu2eV3QGzunMQmSVyEJklchCZJXIQmSVyEJklKiyIJJ0raaek3ZLWFbUfs7KpiP8TSZoD/BQ4B9gH3AVcEBH3931nZiUrKhO9GtgdEQ9FxFPADcDKgvZlVqpnF/S8C4G9Lbf3Aa9pt7EkXzZhVTQREfM6bVRUEHUkaQ2wpqz9m+XwcJ6NigqiMWBxy+1FWdvvRMQGYAM4E1m9FRVEdwHLJC2lETznA39Z0L6sjbXb1066vf4V60vqyXArJIgi4qikS4H/AuYAGyNiRxH7sumawTM1aNq1W5pCpri77oSHc32RN0gcTLltjYgVnTbyFQtDopvAaG4zdbhnvXEQDYFeMosDqX8cRGapIqL0BQgvvS1rt6+dcb3bx3Xz2BFatuT5/XUmMktVdhZyJup9mSl75Mko7bZxNpq2OBONgomJCSYmJsruxkgr7do564+5c+cC/C6Qmrdn4/8P9ZczkVkiZ6IhkScDWUHKnlTwxEJvS7tJgImJiZiYmOj7847okmtiwZloyDgjDZ7PiYaUZ+0Gx5loSDkjDY4z0ZBzRiqeM9GQc0YqnjORWaKeg0jSYknflXS/pB2S1mbtl0sak7QtW87rX3fNqidlOHcU+GhE3C3phcBWSbdn930xIj6f3j2z6us5E0XEeETcna0fAR6gUbTRBmD9K9ZP+lRqPyYP1m5f6+vqetCXcyJJS4BXAj/Mmi6VtF3SRkkn9GMfNjtPIJQnOYgkvQC4GfhwRDwOXAm8GFgOjANXtHncGklbJG1J7YNZmZKCSNJzaATQVyLiFoCIOBART0fEM8BVNIrbTxMRGyJiReQoSWRWaQkXjQq4DviXKe0LWtY/AtzgC1CLW/pxwahrLLRdCr8A9c+A9wD3StqWtX0MuEDS8qwTe4APJuzDrPrK/hiEM1H6kpJFnIFmXVxjYZT0UoTRhRv7w0E0BHqpZup63P3jIBoS3QSSA6i//K0QQ8hfrdI3ub4VwkE0xPwlX8kcRGaJ/P1EZoNQi0+2nvz2y8vugo2g/V+7PNd2zkRmiRxEZokcRGaJHERmiRxEZokcRGaJHERmiRxEZokcRGaJkq9YkLQHOAI8DRyNiBWSTgRuBJbQ+Ij46oj4eeq+zKqoX5noDRGxvOVivXXAHRGxDLgju202lIoazq0Ers3WrwXeXtB+zErXjyAK4NuStkpak7XNj4jxbH0/ML8P+zGrpH5cxf3aiBiT9CLgdkk/ab0zImKmzwtlAbdmavtM5i0+uQ/dNOvO/pzbJQdRRIxlPw9KupVGxdMDkhZExLikBcDBGR63AdgAnT+U9+jevIdjNnhJQSTp+cCzIuJItv5m4NPAbcCFwGeyn19P2Y8zkZVhUJloPnCrpOZzfTUiviXpLmCTpIuAh4HVifsxq6ykIIqIh4A/naH9EPCmlOc2qwtfsWCWyEFklqgWhUrmLfTEglVXLYLo0TFPcVt11SKInImsynxOZJbIQWSWqBbDuRNPnld2F8zaqkUQPbb/0bK7YNZWLYLImciqzOdEZolqkYlOmD+3L89zzpF7Jt2+/YXTLvvr6LhvfXnS7SfO/ZukPo2a1vegl9e/imoRRD8/MJH0+NXHjc3Y3nxDNz2xcNbHL/zxprb3NYNq7JW+UL2Tqe/DOUfu6fja10EtgqjXTDQ187TTfHOn/mWcmnVm0ww0Z6bpZnsf2r32dVKLIOKUHV1tfs7Ooz3tpvlm/+AHP+jp8fD7wHviA6/v+TmGQZ73oPV1Po7fr9fttatHED1y+qx358047aQETTvHbfzetLZRyFKd3os8r3XztavL61WPIGrJRL1mmVZFBE0eMw0P6/ZXt51O70svr3ldsnrPQSTppTSqnDadCnwCOB74a6D5H9KPRcQ3e+4h6YFTVtDkMVPGWrVqVQk96c3Bg9Nq0EzSj9e++RoN+nW5Kud2ipi10E6+J5HmAGPAa4D3A7+MiM938fhZO7FpU/vZsZlUOWhSVCm4BhE87QzqdTj77LO3tlT1batfw7k3AQ9GxMNZ0ZKBGtagmerWW2+d1nbRRWnng936yU9mP08ZxHvRfB2KPPZOx9mqX0F0PnB9y+1LJb0X2AJ8tJ/F7EclYPK6+urpU8PvXHp33/czfsrfznp/Ge9L89j7cbydjm82ycM5SccAjwCnR8QBSfOBCRrlhf8JWBARH5jhca0VUM+YbR9r165N6qPBmpN29fS4HX/yvlnvr9IftW6OsdNxAaxevXpgw7m3AndHxAGA5k8ASVcB35jpQd1UQLV0Gw4tm9b27oN/3nb7fauenPX5qhQ8Tc1jnOm4Oh1Pin4E0QW0DOWa5YOzm6uA+/qwDyvAjS/6Tvs7qxcjuc14XAUeT9JV3Fnp4HOAW1qaPyfpXknbgTcAH0nZh+Wzfv36srswslIroP4KOGlK23uSemRWM/48kVkiB5FZIgeRWSIHkVkiB9GQ8D+ky+MgMkvkIDJL5CAyS+QgMkvkIDJL5CAyS+QgMkvkIDJL5CAyS+QgMkvkIDJLVIsKqGccua3sLpi1lSuIJG0E3gYcjIiXZW0n0qiAugTYA6yOiJ+rUXhuPXAe8ATwvohIqmm079jnpDzcrFB5M9E1wJeA61ra1gF3RMRnJK3Lbv8Djeo/y7LlNcCV2c+ejb/AQWTVlSuIIuJOSUumNK8Ezs7WrwX+h0YQrQSui0ZBu82Sjp9SAahrC375214fala4lHOi+S2BsR+Yn60vBPa2bLcva5sURFOKN87KmciqrC8TCxER3RZg7KZ4ozORVVlKEB1oDtMkLQCaXxMwBixu2W5R1tYzZyKrspQgug24EPhM9vPrLe2XSrqBxoTC4ZTzIXAmsmrLO8V9PY1JhLmS9gGfpBE8myRdBDwMNL8++5s0prd305jifn9qJ52JrMryzs5d0OauN82wbQCXpHRqKmciq7JaXLHgTGRVVosgWnD842V3waytWgTR+C/+oOwumLVViyByJrIqq0UQORNZldUiiJyJrMpqEUTORFZltQgiZyKrsloEkTORVVktgmjsWJeCsOqqRRAt/PUzZXfBrK1aBJEzkVVZLYLImciqzH/izRLVIhN5OGdVVosg8nDOqqwWQeRMZFXWMYjaVD/9Z+AvgKeAB4H3R8Qvstp0DwA7s4dvjoiLUzvpTGRVlicTXcP06qe3A5dFxFFJnwUuo1G4EeDBiFjez046E1mVdQyimaqfRsS3W25uBt7Z325N5kxkVdaPc6IP0Chs37RU0o+Bx4F/jIjvz/SgbiqgOhNZlSUFkaSPA0eBr2RN48AfRcQhSWcAX5N0ekRMuwy7mwqoZlXW8594Se+jMeHwV1mZLCLiNxFxKFvfSmPS4SV96KdZZfWUiSSdC/w98PqIeKKlfR7wWEQ8LelUGl+v8lBqJ/cc45JZVl15prhnqn56GfBc4PbGd3r9bir7LODTkn4LPANcHBGPpXZyyVMu3miDl/eb6fLMzs1U/fTqNtveDNycc9+5ORNZldXiigVnIitD3zJRFTgTWZXVIoiciawMzkRmA1KLIHImsjI4E5kNSC2CyJnIyuBMZDYgvjzaLFEtMpHN7nWPvm7S7e/Pm/HTJ1YQZ6KamxpA7dqsOA4is0QOIrNEDiKzRA4is0QOIrNEDiKzRB2DSNJGSQcl3dfSdrmkMUnbsuW8lvsuk7Rb0k5Jbymq42ZVkScTXQOcO0P7FyNiebZ8E0DSacD5wOnZY74saU6/OmuTzfb/IP+vaHA6BlFE3AnkLTayErghK531M2A38OqE/plVXso50aWStmfDvROytoXA3pZt9mVt00haI2mLpC0JfTArXa9BdCXwYmA5jaqnV3T7BBGxISJWRMSKHvtgVgk9XYAaEQea65KuAr6R3RwDFrdsuihrM2D//+3v7xM+b8D7y5x58kmFPG/VFPp5IkkLImI8u7kKaM7c3QZ8VdIXgFNoVED9US/7aDUsH8or5lfaytZrBdSzJS0HAtgDfBAgInZI2gTcT6PQ/SUR8XQxXTerBmW16MvtRIdvhXjHJ14+qK701eb9hwrfxyMPPTLr/aecekrhfRjW4d0tn753a55zdn8or2amBk2nIOl2e+ueg6hCOmUV6D4Ipm5fxD5G3UgG0a+3LO68UaJti7Z1/ZhB/PIWsY/N+w/xrue9q+/PO9XeP/zvwvfRi5ELojIDqArnL3n00s+bnryp8EBafPiNlQykkQqisjNQEUFSRGD22s9RDaSRCaLFh9/Y+K9VgW568qZid0C+c5rZti8629305E0s37e80H3AYo5dsbfzZgMyMkFUhmGdGRvW4+qVg6hA/fjl6jbzdPt8gxzuDauR+GTr4sNvLHwfgxjK1UUvM5PdGsT5bV4jkYl27dpV/E4WFb+LOlm2rOATUGAv1TgvGokgKksRQ6fU4V0RQ8xRH94N/XCu7GntUTWI4e0ghul5OBPVTLeZadSzxCAMfRANYmy+7cl8mahK/xidTb9mBAdxLnpsBT4XPdTDOc/KlWtUZumGOojMBiHPJ1s3Am8DDkbEy7K2G4GXZpscD/wiIpZLWgI8AOzM7tscERf3u9PDahAfU+j3P28t3znRNcCXgOuaDRHx7ua6pCuAwy3bPxgRRV88NbJSP5Rn/dcxiCLizizDTCNJwGqgGnONLX69ZTG7KPbEtgpT21UPkm2LthX/WaPDy0q9sjv1nOh1wIGIaP1tXSrpx5K+J8m1bG3opU5xXwBc33J7HPijiDgk6Qzga5JOj4jHpz5Q0hpgTeL+zUrXcyaS9GzgHcCNzbasBvehbH0r8CDwkpkeX2QFVF+lUC1Df/VCRHRcgCXAfVPazgW+N6VtHjAnWz+VRvXTE3M8f3jxUsFlS574yPP9RNcD/wu8VNI+SRdld53P5KEcwFnAdknbgP8ALo6IvN8oYVZLtSjeaFYSF2+02b38Ux+adPveT1456za93D8S8oz5il4of+w7csvLP/WhSevNpdM23dw/BEt/zonMbHYOIrNEDiKzRA4is0QOIrNE/j/RCPMUd0e5/k/kIDJrL1cQeThnlshXLFTMIIZYeYZgQz5M6ysHUcUVHTD9CNpR53OiCnI2qgxPLNTR1ABqav0lnmmb1Pu7fY4R4YkFs0FwJjJrz5nIbBDyfDx8saTvSrpf0g5Ja7P2EyXdLmlX9vOErF2S/lXSbknbJb2q6IMwK1OeTHQU+GhEnAacCVwi6TRgHXBHRCwD7shuA7yVxvd0L6NREmvkzkZttHQMoogYj4i7s/UjNGptLwRWAtdmm10LvD1bXwlcFw2bgeMlLeh7z80qoqtzoqyc8CuBHwLzI2I8u2s/MD9bXwiTvkxzX9ZmNpRyX7Eg6QXAzcCHI+LxRhnuhoiIbmfYXAHVhkWuTCTpOTQC6CsRcUvWfKA5TMt+Hszax4DWEqSLsrZJiqyAajZIeWbnBFwNPBARX2i56zbgwmz9QuDrLe3vzWbpzgQOtwz7zIZPjnJWr6VRPmg7sC1bzgNOojErtwv4Dlm5YEDAv9Gow30vsMIls7zUdMlVMstXLJi15ysWzAbBQWSWyEFklshBZJbIQWSWqCo1FiaAX2U/h8Vchud4hulYIP/x/HGeJ6vEFDeApC3DdPXCMB3PMB0L9P94PJwzS+QgMktUpSDaUHYH+myYjmeYjgX6fDyVOScyq6sqZSKzWio9iCSdK2lnVthkXedHVI+kPZLulbRN0pasbcZCLlUkaaOkg5Lua2mrbSGaNsdzuaSx7D3aJum8lvsuy45np6S3dL3Dkr81fA6Nj0ycChwD3AOcVmafejyOPcDcKW2fA9Zl6+uAz5bdz1n6fxbwKuC+Tv2n8TGY/6TxkZczgR+W3f+cx3M58HczbHta9nv3XGBp9vs4p5v9lZ2JXg3sjoiHIuIp4AYahU6GQbtCLpUTEXcCj01prm0hmjbH085K4IaI+E1E/AzYTeP3Mreyg2hYipoE8G1JW7PaEdC+kEtdDGMhmkuzIejGluF18vGUHUTD4rUR8SoaNfcukXRW653RGDfUdhq07v3PXAm8GFgOjANX9OuJyw6iXEVNqi4ixrKfB4FbaQwH2hVyqYukQjRVExEHIuLpiHgGuIrfD9mSj6fsILoLWCZpqaRjgPNpFDqpDUnPl/TC5jrwZuA+2hdyqYuhKkQz5bxtFY33CBrHc76k50paSqNy74+6evIKzKScB/yUxqzIx8vuTw/9P5XG7M49wI7mMdCmkEsVF+B6GkOc39I4J7ioXf/poRBNRY7n37P+bs8CZ0HL9h/Pjmcn8NZu9+crFswSlT2cM6s9B5FZIgeRWSIHkVkiB5FZIgeRWSIHkVkiB5FZov8Hze6dgW7SXKgAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(obs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(210, 160, 3)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "obs.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We try to get the dimensions of the interesting parts of the observation:\n",
    "* The radar part (that is in the top middle part of the frame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7fbee37d9080>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(obs[3:36,74:96])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* The view from the tank's cockpit, restrained to the green field (and a little of the background mountains) which will contain the moving enemies as well as the projectiles' range and most importantly the cursor indicating what is directly in front of our tank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7fbee37b0668>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(obs[80:178,8:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We define our preprocessing functions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_gray(img):\n",
    "    # Convert images to grayscale with values between 0 and 1\n",
    "    return color.rgb2gray(img).astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def downsample(img):\n",
    "    # Downsampling an image for faster computing\n",
    "    return img[::2, ::2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing(obs):\n",
    "    radar = obs[3:36,74:96]\n",
    "    scene = obs[80:178,8:]\n",
    "    radar = to_gray(radar)\n",
    "    scene = downsample(to_gray(scene))\n",
    "    return radar, scene"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "radar, scene = preprocessing(obs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7fbee3791b70>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(radar, cmap=\"gray\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7fbee36e8be0>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(scene, cmap=\"gray\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(33, 22) (49, 76)\n"
     ]
    }
   ],
   "source": [
    "print(radar.shape, scene.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The agent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imports:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Input, Flatten, Dense, Concatenate, Multiply, MaxPooling2D\n",
    "from keras.layers.convolutional import Conv2D\n",
    "from keras.models import Model, Sequential, load_model\n",
    "from keras.optimizers import RMSprop\n",
    "\n",
    "from keras import backend as K\n",
    "from keras.utils import plot_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will be giving the model a number of frames at a time (the time of the last projectile sent can be a determining factor, so the agent may need it)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_frames = 2 #Number of input frames per input\n",
    "n_actions = 18 #Dimension of action space\n",
    "batch_size = 128 #Number of entries (states+actions) to feed the NN\n",
    "memory_size = 10000 # Memory size for experience replay\n",
    "n_repetition = 3 # Number of frames for which same action is repeated"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hyperparameters for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "gamma = 0.99\n",
    "epsilon = 1e-6\n",
    "learning_rate = 0.00025"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use a Huber loss function for our model to prevent heavy penalization of high errors (linear instead of quadratic). We will implement the function so it can be used within a Keras neural network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def huber_loss(a, b):\n",
    "    e = a - b\n",
    "    quad = e**2 / 2\n",
    "    lin = abs(e) - 1/2\n",
    "    use_lin = (abs(e) > 1.0)\n",
    "    use_lin = K.cast(use_lin, 'float32')\n",
    "    return use_lin * lin + ( 1 - use_lin) * quad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us define our model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model():\n",
    "    \n",
    "    # Shape of entries\n",
    "    scene_shape = (n_frames, 49, 76,)\n",
    "    radar_shape = (n_frames, 33 * 22,) # Since we will be using a fully connected network here,\n",
    "                                    # we will provide a flattened version of the radar frame\n",
    "    \n",
    "    # Input layers\n",
    "    scene_inp = Input(scene_shape, name='scenes')\n",
    "    radar_inp = Input(radar_shape, name='radars')\n",
    "    actions_inp = Input((n_actions,), name='actions')\n",
    "    \n",
    "    # Hidden layers for the scene\n",
    "    conv1 = Conv2D(filters=8,\n",
    "                   kernel_size=(8, 8),\n",
    "                   strides=(4, 4),\n",
    "                   activation='relu',\n",
    "                   data_format=\"channels_first\")(scene_inp)\n",
    "    \n",
    "    maxpool1 = MaxPooling2D(pool_size=(4, 4),\n",
    "                            strides=(4, 4))(conv1)\n",
    "   \n",
    "    scene_output = Flatten('channels_first')(maxpool1)\n",
    "    \n",
    "    # Hidden layers for the radar\n",
    "    \n",
    "    radar_hidden = Dense(512, activation=\"relu\")(radar_inp)\n",
    "    radar_hidden_flattened = Flatten()(radar_hidden)\n",
    "    radar_output = Dense(128, activation=\"relu\")(radar_hidden_flattened)\n",
    "        \n",
    "    # Last hidden layer\n",
    "    hidden_last = Concatenate(axis=1)([scene_output, radar_output])\n",
    "    \n",
    "    # Output\n",
    "    output = Dense(n_actions, activation='softmax')(hidden_last)\n",
    "\n",
    "    # Multiply by the actions (mask for training)\n",
    "    filtered_output = Multiply()([output, actions_inp])\n",
    "    \n",
    "    # Create the model\n",
    "    model = Model(input=[scene_inp, radar_inp, actions_inp], \n",
    "                  output=filtered_output,\n",
    "                 )\n",
    "    \n",
    "    # Optimizer choice and tuning\n",
    "    rms = RMSprop(lr = learning_rate)\n",
    "    \n",
    "    # Compiling\n",
    "    model.compile(optimizer=rms, loss=huber_loss)\n",
    "    \n",
    "    return model\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defining the model and visualising its graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lotfi/.local/lib/python3.6/site-packages/ipykernel_launcher.py:42: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=[<tf.Tenso..., outputs=Tensor(\"mu...)`\n"
     ]
    }
   ],
   "source": [
    "model_sample= model()\n",
    "plot_model(model_sample,\n",
    "           to_file='model.png',\n",
    "           show_shapes=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Functions for preprocessing the observation and choosing an action:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stack_frames(stacked_radars, stacked_scenes, observation):\n",
    "    radar, scene = preprocessing(observation)\n",
    "    if (len(stacked_radars) < n_frames):\n",
    "        for _ in range(n_frames):\n",
    "            stacked_radars.append(radar)\n",
    "            stacked_scenes.append(scene)\n",
    "    else:\n",
    "        stacked_radars.append(radar)\n",
    "        stacked_scenes.append(scene)\n",
    "    return stacked_radars, stacked_scenes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def choose_action(model, stacked_radars, stacked_scenes, batch_size=1):\n",
    "# Choose the best action according to the model's prediction\n",
    "\n",
    "    # Reshaping for the model to use\n",
    "    radars = list(stacked_radars)\n",
    "    radars = np.reshape(radars, (batch_size, n_frames, 22 * 33))\n",
    "    \n",
    "    scenes = list(stacked_scenes)\n",
    "    scenes = np.reshape(scenes, (batch_size, n_frames, 49, 76))\n",
    "    \n",
    "    \n",
    "    # Predicting the output for a vector of ones\n",
    "    prediction = model.predict([scenes, radars, np.ones((1,n_actions))])\n",
    "    \n",
    "    # Returning the prediction with the max Q-value\n",
    "    return np.argmax(prediction[0][-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Playing a game with the current model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_game(n_games, model):\n",
    "    \n",
    "    rew_max = 0\n",
    "    \n",
    "    for _ in range(n_games):\n",
    "        \n",
    "        env.reset()\n",
    "        \n",
    "        rew_total = 0\n",
    "        action = 0\n",
    "        \n",
    "        done = False\n",
    "        is_terminal = np.zeros((1, 18))\n",
    "        \n",
    "        stacked_radars = deque([], maxlen=n_frames)\n",
    "        stacked_scenes = deque([], maxlen=n_frames)\n",
    "        \n",
    "        previous_radars = list()\n",
    "        previous_scenes = list()\n",
    "        \n",
    "        while not done :\n",
    "            \n",
    "            if RENDER:\n",
    "                env.render()\n",
    "                time.sleep(0.01)\n",
    "            \n",
    "            for _ in range(n_repetition):\n",
    "                observation, rew, done, info = env.step(action)\n",
    "            \n",
    "            rew += 0.1 # We reward our agent for surviving\n",
    "            rew_total += rew\n",
    "            \n",
    "            stacked_radars, stacked_scenes = stack_frames(stacked_radars, stacked_scenes, observation)\n",
    "            \n",
    "            action = choose_action(model, stacked_radars, stacked_scenes)\n",
    "            \n",
    "            if done:\n",
    "                is_terminal[0,action] = True\n",
    "                        \n",
    "            \n",
    "        rew_max = max(rew_max, rew_total)\n",
    "        env.close()\n",
    "    \n",
    "    return rew_max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "53.30000000000049"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_game(1, model_sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training the agent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Memory for experience replay\n",
    "We will be using a buffer (a ring buffer specifically) in order to put a limit to the memory usage (and prevent any saturation or malfunctioning of our agent)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RingBuf:\n",
    "    \n",
    "    def __init__(self, size):\n",
    "        # We allocate one extra element, so that self.start == self.end always means the buffer is empty\n",
    "        self.data = [None] * (size + 1) # Size will indicate the size of memory we want to allocate\n",
    "        self.start = 0\n",
    "        self.end = 0\n",
    "        \n",
    "    def append(self, element):\n",
    "        self.data[self.end] = element\n",
    "        self.end = (self.end + 1) % len(self.data)\n",
    "        # end == start means the buffer has one too many elements\n",
    "        # We then remove the first element by incrementing start\n",
    "        if (self.end == self.start):\n",
    "            self.start = (self.start + 1) % len(self.data)\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        return self.data[(self.start + index) % len(self.data)]\n",
    "    \n",
    "    def __len__(self):\n",
    "        if (self.end < self.start):\n",
    "            return (self.end + len(self.data) - self.start)\n",
    "        else:\n",
    "            return (self.end - self.start)\n",
    "        \n",
    "    def __iter__(self):\n",
    "        for i in range(len(self)):\n",
    "            yield self[i]\n",
    "    \n",
    "    def get_sample(self, size):\n",
    "        l = list()\n",
    "        for _ in range(size):\n",
    "            if self.end < self.start:\n",
    "                i = random.randint(0, len(self))\n",
    "            l.append(self.data[i])\n",
    "        return l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "memory = RingBuf(memory_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that our model and memory are defined, we will implement a function that will run a fitting iteration: We will be using a Deep Q-learning approach, improving our network everytime the agent makes an action. When fitting, we fit a new model using the Q-values from a target model for more stability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_iteration(model, target_model, start_scenes, start_radars, actions, rewards, next_scenes, next_radars, is_terminal):\n",
    "    \n",
    "    # First, we predict the Q values of the next states. We pass ones as the \"mask\".\n",
    "    next_Q_values = target_model.predict([next_scenes, next_radars, np.ones((batch_size, n_actions))])\n",
    "    \n",
    "    # The Q value a terminal state is 0 by definition\n",
    "    next_Q_values[is_terminal] = 0\n",
    "    \n",
    "    # We apply the formula of the Q value\n",
    "    Q_values = rewards + gamma * np.max(next_Q_values, axis=0)\n",
    "    \n",
    "    # Fit the model.\n",
    "    model.fit([start_scenes, start_radars, actions], actions * Q_values[:, None], nb_epoch=2, batch_size=len(start_scenes), verbose=0)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A function that returns the probability for epsilon-greedy exploration:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def epsilon_from_iter(i):\n",
    "    if (i > epsilon):\n",
    "        return 0.1\n",
    "    else:\n",
    "        return (1 - epsilon * 0.9 * i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A utility function to save the model to a file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def copy_model(model):\n",
    "    model.save('tmp_model')\n",
    "    return load_model('tmp_model', custom_objects={'huber_loss': huber_loss})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_train(n_games, model, memory):\n",
    "    \n",
    "    i = 0\n",
    "    rew_max = 0\n",
    "    \n",
    "    for _ in range(n_games):\n",
    "    \n",
    "        j = 0\n",
    "        env.reset()\n",
    "\n",
    "        rew_total = 0\n",
    "        action = 0\n",
    "        done = False\n",
    "        is_terminal = np.zeros((1, n_actions))\n",
    "\n",
    "        stacked_radars = deque([], maxlen=n_frames)\n",
    "        stacked_scenes = deque([], maxlen=n_frames)\n",
    "        previous_radars = list()\n",
    "        previous_scenes = list()\n",
    "\n",
    "        while not done:\n",
    "\n",
    "            if RENDER:\n",
    "                env.render()\n",
    "\n",
    "            for _ in range(n_repetition):\n",
    "                observation, rew, done, info = env.step(action)\n",
    "\n",
    "            rew += 0.1 \n",
    "            rew_total += rew\n",
    "\n",
    "            previous_radars = deepcopy(stacked_radars)\n",
    "            previous_scenes = deepcopy(stacked_scenes)\n",
    "\n",
    "            stacked_radars, stacked_scenes = stack_frames(stacked_radars, stacked_scenes, observation)\n",
    "\n",
    "            if np.random.uniform() > epsilon_from_iter(i) and len(stacked_radars) == n_frames:\n",
    "                action = choose_action(model, stacked_radars, stacked_scenes)\n",
    "            else:\n",
    "                action = env.action_space.sample()\n",
    "\n",
    "\n",
    "            # Preparing data for the memory \n",
    "            if done:\n",
    "\n",
    "                is_terminal[0, action] = 1\n",
    "\n",
    "            if (j > 0):\n",
    "\n",
    "                start_radars = np.reshape(list(previous_radars),\n",
    "                                          (n_frames, previous_radars[0].shape[0]*previous_radars[0].shape[1]))\n",
    "                next_radars = np.reshape(list(stacked_radars),\n",
    "                                         (n_frames, stacked_radars[0].shape[0]*stacked_radars[0].shape[1]))\n",
    "\n",
    "                start_scenes = np.reshape(list(previous_scenes),\n",
    "                                          (n_frames,\n",
    "                                           previous_scenes[0].shape[0],\n",
    "                                           previous_scenes[0].shape[1]))\n",
    "                next_scenes = np.reshape(list(stacked_scenes),\n",
    "                                         (n_frames,\n",
    "                                          stacked_scenes[0].shape[0],\n",
    "                                          stacked_scenes[0].shape[1]))\n",
    "\n",
    "                actions = np.zeros((1,n_actions))\n",
    "                actions[0,action] = 1\n",
    "\n",
    "                is_terminal = np.zeros((1, n_actions), dtype=np.int16)\n",
    "                if done:\n",
    "                    is_terminal[0, action] = 1\n",
    "\n",
    "                memory.append([start_radars,\n",
    "                               start_scenes,\n",
    "                               actions,\n",
    "                               rew,\n",
    "                               next_radars,\n",
    "                               next_scenes,\n",
    "                               is_terminal])\n",
    "\n",
    "\n",
    "            # Stabilizing by copying the model every 10000 frames\n",
    "            if ((i % 10000) == 0 or (i < 5000 and i % 100 == 0)):\n",
    "                target_model = copy_model(model)\n",
    "\n",
    "            # Fitting the model every 256 frames\n",
    "            if (i > memory_size):\n",
    "\n",
    "                sample = memory.get_sample(batch_size)\n",
    "\n",
    "                start_radars, start_scenes, actionss, rews, next_radars, next_scenes, is_terminals = [], [], [], [], [], [], []\n",
    "\n",
    "                for s in sample:\n",
    "\n",
    "                    start_radars.append(s[0])\n",
    "                    start_scenes.append(s[1])\n",
    "                    actionss.append(s[2])\n",
    "                    rews.append(s[3])\n",
    "                    next_radars.append(s[4])\n",
    "                    next_scenes.append(s[5])\n",
    "                    is_terminals.append(s[6])\n",
    "\n",
    "                start_scenes = np.reshape(start_scenes, (batch_size, n_frames, 49, 76))\n",
    "                start_radars = np.reshape(start_radars, (batch_size, n_frames, 22 * 33))\n",
    "                actionss = np.reshape(actionss, (batch_size, n_actions))\n",
    "                rews = np.reshape(rews, (batch_size, 1))\n",
    "                next_scenes = np.reshape(next_scenes, (batch_size, n_frames, 49, 76))\n",
    "                next_radars = np.reshape(next_radars, (batch_size, n_frames, 22 * 33))\n",
    "                is_terminals = np.reshape(is_terminals, (batch_size, n_actions))\n",
    "\n",
    "                print(is_terminals[0])\n",
    "\n",
    "                model = fit_iteration(model,\n",
    "                                      target_model, \n",
    "                                      start_scenes,\n",
    "                                      start_radars,\n",
    "                                      actionss,\n",
    "                                      rews,\n",
    "                                      next_scenes,\n",
    "                                      next_radars,\n",
    "                                      is_terminals)\n",
    "            \n",
    "            rew_max = max(rew_max, rew_total)\n",
    "\n",
    "            i += 1\n",
    "            j += 1\n",
    "    print(rew_max)        \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lotfi/.local/lib/python3.6/site-packages/ipykernel_launcher.py:42: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=[<tf.Tenso..., outputs=Tensor(\"mu...)`\n"
     ]
    }
   ],
   "source": [
    "model_to_train = model()\n",
    "\n",
    "memory = RingBuf(memory_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2051.7999999999847\n"
     ]
    }
   ],
   "source": [
    "model = run_train(10, model_to_train, memory)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
